{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "56460bdb0ccc4612f8b9f917f6ebe50a",
     "grade": false,
     "grade_id": "cell-b2a16d2a831bd2cc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# CS448 - Lab 4: 3D Audio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "492d231cc8440ceacf887b7ebb317a0d",
     "grade": false,
     "grade_id": "cell-89aedf576827399f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In this lab we will learn how to create 3D sounds for headphone playback. We will make use of simple filters and HRTFs to create static and moving sources. Use the three sounds fly.wav, helicopter.wav, and crumble.wav in the lab archive as sources for the 3D recording that you will create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_GRAPHS = False\n",
    "SUBMISSION_MODE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORTS & SETUP ###\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('bmh')\n",
    "plt.rcParams[\"figure.figsize\"] = (4, 3)\n",
    "\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import lfilter, convolve, fftconvolve\n",
    "\n",
    "# Importing the HRTF functions\n",
    "# referencing https://stackoverflow.com/questions/4383571/importing-files-from-different-folder\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"./hrtf\")\n",
    "from load_hrtf import load_hrtf as hrtf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### UTILITIES ###\n",
    "\n",
    "\n",
    "# Sound player function that plays array \"x\" with a sample rate \"rate\", and labels it with \"label\"\n",
    "def sound(x, rate=8000, label=''):\n",
    "    from IPython.display import display, Audio, HTML\n",
    "    display(\n",
    "        HTML('<style> table, th, td {border: 0px; }</style> <table><tr><td>' +\n",
    "             label + '</td><td>' + Audio(x, rate=rate)._repr_html_()[3:] +\n",
    "             '</td></tr></table>'))\n",
    "\n",
    "\n",
    "# Function that normalizes a signal\n",
    "def normalize_signal(x):\n",
    "    return x / np.max(np.abs(x))\n",
    "\n",
    "\n",
    "# Function that plots the spectrogram of a sound\n",
    "def plot_spectrogram(input_sound, fs, title=\"Spectrogram\"):\n",
    "    plt.title(title)\n",
    "    plt.specgram(input_sound, Fs=fs, cmap=\"winter\")\n",
    "    plt.xlabel('Time [sec]')\n",
    "    plt.ylabel('Frequency [Hz]')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the input sounds\n",
    "fname_crumble = 'crumble.wav'\n",
    "fs_crumble, input_sound_crumble = wavfile.read(f'./data/{fname_crumble}')\n",
    "input_sound_crumble = normalize_signal(input_sound_crumble)\n",
    "sound(input_sound_crumble, rate=fs_crumble, label=fname_crumble)\n",
    "\n",
    "fname_fly = 'fly.wav'\n",
    "fs_fly, input_sound_fly = wavfile.read(f'./data/{fname_fly}')\n",
    "input_sound_fly = normalize_signal(input_sound_fly)\n",
    "sound(input_sound_fly, rate=fs_fly, label=fname_fly)\n",
    "\n",
    "fname_heli = 'helicopter.wav'\n",
    "fs_heli, input_sound_heli = wavfile.read(f'./data/{fname_heli}')\n",
    "input_sound_heli = normalize_signal(input_sound_heli)\n",
    "sound(input_sound_heli, rate=fs_heli, label=fname_heli)\n",
    "\n",
    "if (PLOT_GRAPHS):\n",
    "    plot_spectrogram(input_sound_crumble,\n",
    "                     fs_crumble,\n",
    "                     title=f\"Spectrogram of {fname_crumble}\")\n",
    "\n",
    "    plot_spectrogram(input_sound_fly,\n",
    "                     fs_fly,\n",
    "                     title=f\"Spectrogram of {fname_fly}\")\n",
    "\n",
    "    plot_spectrogram(input_sound_heli,\n",
    "                     fs_heli,\n",
    "                     title=f\"Spectrogram of {fname_heli}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "97767232d3291ae0a2d2d5f79dda02f2",
     "grade": false,
     "grade_id": "cell-572651ac49dd65cc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Part 1: Static sources using ITD/ILD cues"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6104b7fab9123a18a4a1acf31cc46f63",
     "grade": false,
     "grade_id": "cell-5707634d2e359647",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Assume the following source locations: \n",
    "\n",
    "- Straight ahead\n",
    "\n",
    "- 45 degrees to the left\n",
    "\n",
    "- 80 degrees to the right\n",
    "\n",
    "- 160 degrees to the left\n",
    "\n",
    "For each location find the source’s delay between the two ears (assume a source distance of 2 meters), and design two filters that will simulate that ITD and ILD features (feel free to round the IDT delays to an integer sample size). Assume that when sounds come from the side of the head the attenuation at the contralateral ear is by a factor of 0.7. From sounds coming medial plane (between the ears) there will be no attenuation due to the head. For positions moving from the medial plane towards the sides you can interpolate between no attenuation and a factor of 0.7. Design and plot the filters that correspond to the locations shown above and use them to make 3D sounds with the following sounds:\n",
    "\n",
    "- Crumbling paper: [https://drive.google.com/uc?export=download&id=1bsZArYwMftsuCLdMknRomz4kAJWT-Uhv ]\n",
    "\n",
    "- Fly: [https://drive.google.com/uc?export=download&id=1bswUsI28yJOUQuNLvNxq3pu9qj0bb8ne ]\n",
    "\n",
    "- Helicopter: [https://drive.google.com/uc?export=download&id=1c8YhNNLmaO7CA2dJNCkBsB9MY0HjHDRL ]\n",
    "\n",
    "Listen to the result through headphones and verify that they sound somewhat localized (it won’t sound perfect, but it should be believable).  There is no need to render all three sounds, since the notebook will become very large and hard to upload.  At submission time just render one sound, but make sure that you listen to all three and that they sound good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3fcc0fc47c7a0c09fba41f0c6a1ce527",
     "grade": true,
     "grade_id": "cell-105baab0631e098f",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "737a7645e6d8c0be2ab92f3ba7dafa96",
     "grade": false,
     "grade_id": "cell-f828ea3a2736c0c7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Part 2. Static sources using HRTFs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eb7eec159d12ed3eff1722a669eaf822",
     "grade": false,
     "grade_id": "cell-6c5fbbbb60e8cdac",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Download the HTTF archive from [https://drive.google.com/uc?export=download&id=1vFzSo-zlNFI-q2T9yvRRmOeZ-elZ8lW3 ]. In that directory you will also find code for the function load_hrtf which returns the left and right HRTF filters given as input a source’s azimuth and elevation. These filters will be much better than the ITD/ILD filters for localizing sounds.\n",
    "\n",
    "Apply the HRTFs on the given sources and create 3D sounds that correspond to the locations given above. For each source, you will beed to convolve it with the left and right HRTF of the desired position and generate two sounds, one for each channel. Verify that they sound correct using headphones; are they better than before? What differences do you observe? When you use these make sure that the sample rates of the HRTFs and the sounds you convolve them with match.  The HRTFs are sampled at 44.1kHz.\n",
    "\n",
    "Once again, just render one example before submission (the same as before so that we can compare)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "30ccb0b59afcc2e336969d3ddccf7b68",
     "grade": true,
     "grade_id": "cell-7aa20c8c6db3869b",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "09136705ec12de8e825442459f422b58",
     "grade": false,
     "grade_id": "cell-c2eb36b7ccda595f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Part 3. Dynamic Sources with HRTFs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8ae73ad74b6ec19d56c83a9400dcfb4b",
     "grade": false,
     "grade_id": "cell-63eaf3eb61463897",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In this part you will need to make a moving sound source. In order to do so we will make use of a fast convolution routine based on your STFT code from lab 1 (ha, you thought you were done with that!). In order to perform fast convolution we can perform an STFT of the sound to use, multiply each time frame of this transform with the DFT of the filter that we want  to impose and then use overlap add to transform back to the time domain.\n",
    "\n",
    "Start by taking each sound from above, and apply your STFT on it. Make sure that the size of the transform is the same as the HRTF’s filter length. The hop size should be the same as the DFT size and you will need to zero pad by as much as the DFT size in order to facilitate the tail of the convolution. Do not use an analysis/synthesis window.\n",
    "\n",
    "Once you compute this STFT, go through its every time frame and element-wise multiply it with the desired HRTF filter to generate the STFT of the left and right sounds. Figure out which HRTF angle to multiply each frame with so that by the end of the sound you will have made it go around your head.\n",
    "\n",
    "Once you perform these operations you will have generated two STFT matrices, one for the left channel and one for the right. Use your inverse STFT routine and play the stereo sound through your headphones. You should hear a convincing rendering of the original sounds circling around your head.\n",
    "\n",
    "Submit only one of the sounds, but make sure you try it on all and that it sounds ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5919b5f672f4d021a48c07ec3e20c0a2",
     "grade": true,
     "grade_id": "cell-41f181d665283201",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3ff1a53eda0063ee9d7fb15331122010",
     "grade": false,
     "grade_id": "cell-b0124588fbfe89bb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Part 4. Extra credit (required for 4-hour credit registrants)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "91ff910e32fe396a3d00038e9d01090f",
     "grade": false,
     "grade_id": "cell-b3414fb1e822c1df",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Use the file in [https://drive.google.com/uc?export=download&id=1bxQkXcGa57S3G7IRWu9urS-jCPdf5Pif ] to make a short story. This is a 7-channel file of a scene from a really bad B-movie. Each channel contains a different sound. If you play that sound you probably won’t hear most of the content since you won’t have a 7 speaker setup, import it in a multi-channel editor such as Audacity and you will get a sense of what’s in there. Since it sounds so boring you need to add some reverb and 3D-locate the sounds so that it sounds more exciting. Try to make it sound better using what we have done so far. Keep in mind that you can add different amounts of reverb for each sound, and you can dynamically 3D place them as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5faf496e989916afedad8ef8b7263784",
     "grade": true,
     "grade_id": "cell-58aead3226c4d49a",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
