{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "56460bdb0ccc4612f8b9f917f6ebe50a",
     "grade": false,
     "grade_id": "cell-b2a16d2a831bd2cc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# CS448 - Lab 4: 3D Audio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "492d231cc8440ceacf887b7ebb317a0d",
     "grade": false,
     "grade_id": "cell-89aedf576827399f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In this lab we will learn how to create 3D sounds for headphone playback. We will make use of simple filters and HRTFs to create static and moving sources. Use the three sounds fly.wav, helicopter.wav, and crumble.wav in the lab archive as sources for the 3D recording that you will create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RUNNING VARIABLES ###\n",
    "\n",
    "PLOT_GRAPHS = False\n",
    "SUBMISSION_MODE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORTS & SETUP ###\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('bmh')\n",
    "plt.rcParams[\"figure.figsize\"] = (4, 3)\n",
    "\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import convolve\n",
    "\n",
    "# Importing the HRTF functions\n",
    "# referencing https://stackoverflow.com/questions/4383571/importing-files-from-different-folder\n",
    "import sys\n",
    "sys.path.append(\"./hrtf\")\n",
    "from load_hrtf import load_hrtf as hrtf_filter  # I modified this file to change the location of the numpy import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### UTILITIES ###\n",
    "\n",
    "\n",
    "# Sound player function that plays array \"x\" with a sample rate \"rate\", and labels it with \"label\"\n",
    "def sound(x, rate=8000, label=''):\n",
    "    from IPython.display import display, Audio, HTML\n",
    "    display(\n",
    "        HTML('<style> table, th, td {border: 0px; }</style> <table><tr><td>' +\n",
    "             label + '</td><td>' + Audio(x, rate=rate)._repr_html_()[3:] +\n",
    "             '</td></tr></table>'))\n",
    "\n",
    "\n",
    "# Function that normalizes a signal\n",
    "def normalize_signal(x):\n",
    "    return x / np.max(np.abs(x))\n",
    "\n",
    "\n",
    "# Function that plots the spectrogram of a sound\n",
    "def plot_spectrogram(input_sound, fs, title=\"Spectrogram\"):\n",
    "    plt.title(title)\n",
    "    plt.specgram(input_sound, Fs=fs, cmap=\"winter\")\n",
    "    plt.xlabel('Time [sec]')\n",
    "    plt.ylabel('Frequency [Hz]')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the input sounds\n",
    "fname_crumble = \"crumble.wav\"\n",
    "fs_crumble, input_sound_crumble = wavfile.read(f\"./data/{fname_crumble}\")\n",
    "input_sound_crumble = normalize_signal(input_sound_crumble)\n",
    "sound(input_sound_crumble, rate=fs_crumble, label=fname_crumble)\n",
    "\n",
    "if PLOT_GRAPHS:\n",
    "    plot_spectrogram(\n",
    "        input_sound_crumble, fs_crumble, title=f\"Spectrogram of {fname_crumble}\"\n",
    "    )\n",
    "\n",
    "if not (SUBMISSION_MODE):\n",
    "    fname_fly = \"fly.wav\"\n",
    "    fs_fly, input_sound_fly = wavfile.read(f\"./data/{fname_fly}\")\n",
    "    input_sound_fly = normalize_signal(input_sound_fly)\n",
    "    sound(input_sound_fly, rate=fs_fly, label=fname_fly)\n",
    "\n",
    "    fname_heli = \"helicopter.wav\"\n",
    "    fs_heli, input_sound_heli = wavfile.read(f\"./data/{fname_heli}\")\n",
    "    input_sound_heli = normalize_signal(input_sound_heli)\n",
    "    sound(input_sound_heli, rate=fs_heli, label=fname_heli)\n",
    "\n",
    "    if PLOT_GRAPHS:\n",
    "        plot_spectrogram(input_sound_fly, fs_fly, title=f\"Spectrogram of {fname_fly}\")\n",
    "\n",
    "        plot_spectrogram(\n",
    "            input_sound_heli, fs_heli, title=f\"Spectrogram of {fname_heli}\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "97767232d3291ae0a2d2d5f79dda02f2",
     "grade": false,
     "grade_id": "cell-572651ac49dd65cc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Part 1: Static sources using ITD/ILD cues"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6104b7fab9123a18a4a1acf31cc46f63",
     "grade": false,
     "grade_id": "cell-5707634d2e359647",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Assume the following source locations: \n",
    "\n",
    "- Straight ahead\n",
    "\n",
    "- 45 degrees to the left\n",
    "\n",
    "- 80 degrees to the right\n",
    "\n",
    "- 160 degrees to the left\n",
    "\n",
    "For each location find the source’s delay between the two ears (assume a source distance of 2 meters), and design two filters that will simulate that ITD and ILD features (feel free to round the IDT delays to an integer sample size). Assume that when sounds come from the side of the head the attenuation at the contralateral ear is by a factor of 0.7. From sounds coming medial plane (between the ears) there will be no attenuation due to the head. For positions moving from the medial plane towards the sides you can interpolate between no attenuation and a factor of 0.7. Design and plot the filters that correspond to the locations shown above and use them to make 3D sounds with the following sounds:\n",
    "\n",
    "- Crumbling paper: [https://drive.google.com/uc?export=download&id=1bsZArYwMftsuCLdMknRomz4kAJWT-Uhv ]\n",
    "\n",
    "- Fly: [https://drive.google.com/uc?export=download&id=1bswUsI28yJOUQuNLvNxq3pu9qj0bb8ne ]\n",
    "\n",
    "- Helicopter: [https://drive.google.com/uc?export=download&id=1c8YhNNLmaO7CA2dJNCkBsB9MY0HjHDRL ]\n",
    "\n",
    "Listen to the result through headphones and verify that they sound somewhat localized (it won’t sound perfect, but it should be believable).  There is no need to render all three sounds, since the notebook will become very large and hard to upload.  At submission time just render one sound, but make sure that you listen to all three and that they sound good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "speed_of_sound = 343  # m/s\n",
    "attenuation_factor = 0.7  # 1/m\n",
    "source_distance = 2  # m\n",
    "head_width = 0.2  # m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3fcc0fc47c7a0c09fba41f0c6a1ce527",
     "grade": true,
     "grade_id": "cell-105baab0631e098f",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Straight ahead\n",
    "def straight_ahead(input_sound, fs):\n",
    "    # Calculating the distance from the left and right ears\n",
    "    dist_from_l_ear = np.sqrt(source_distance**2 + (head_width / 2) ** 2)\n",
    "    dist_from_r_ear = np.sqrt(source_distance**2 + (head_width / 2) ** 2)\n",
    "\n",
    "    # Calculating the delay for the left and right ears\n",
    "    delay_l_ear = int(dist_from_l_ear / speed_of_sound * fs)\n",
    "    delay_r_ear = int(dist_from_r_ear / speed_of_sound * fs)\n",
    "\n",
    "    # Setting up the left and right ear filters\n",
    "    l_ear_filter = np.zeros(delay_l_ear * 2)\n",
    "    r_ear_filter = np.zeros(delay_r_ear * 2)\n",
    "\n",
    "    l_ear_filter[delay_l_ear] = 1\n",
    "    r_ear_filter[delay_r_ear] = 1\n",
    "\n",
    "    l_chan = convolve(input_sound, l_ear_filter)\n",
    "    r_chan = convolve(input_sound, r_ear_filter)\n",
    "\n",
    "    if PLOT_GRAPHS:\n",
    "        plt.figure()\n",
    "        plt.title(\"Left and right ear filters\")\n",
    "        plt.plot(l_ear_filter)\n",
    "        plt.plot(r_ear_filter)\n",
    "\n",
    "    return np.vstack((l_chan, r_chan))\n",
    "\n",
    "\n",
    "straight_ahead_crumble = straight_ahead(input_sound_crumble, fs_crumble)\n",
    "sound(straight_ahead_crumble, rate=fs_crumble, label=f\"{fname_crumble} straight ahead\")\n",
    "\n",
    "if not SUBMISSION_MODE:\n",
    "    straight_ahead_fly = straight_ahead(input_sound_fly, fs_fly)\n",
    "    sound(straight_ahead_fly, rate=fs_fly, label=f\"{fname_fly} straight ahead\")\n",
    "\n",
    "    straight_ahead_heli = straight_ahead(input_sound_heli, fs_heli)\n",
    "    sound(straight_ahead_heli, rate=fs_heli, label=f\"{fname_heli} straight ahead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 45° to the left\n",
    "def left_45(input_sound, fs):\n",
    "    radians = np.deg2rad(45)\n",
    "\n",
    "    # Calculating the distance from the left and right ears\n",
    "    dist_from_r_ear = np.sqrt(\n",
    "        (source_distance * np.cos(radians)) ** 2\n",
    "        + (source_distance * np.sin(radians) + head_width / 2) ** 2\n",
    "    )\n",
    "    dist_from_l_ear = np.sqrt(\n",
    "        (source_distance * np.cos(radians)) ** 2\n",
    "        + (source_distance * np.sin(radians) - head_width / 2) ** 2\n",
    "    )\n",
    "\n",
    "    # Calculating the delay for the left and right ears\n",
    "    delay_l_ear = int(dist_from_l_ear / speed_of_sound * fs)\n",
    "    delay_r_ear = int(dist_from_r_ear / speed_of_sound * fs)\n",
    "\n",
    "    # Setting up the left and right ear filters\n",
    "    l_ear_filter = np.zeros(delay_l_ear * 2)\n",
    "    r_ear_filter = np.zeros(delay_l_ear * 2)  # Using delay_l_ear for same size arrays\n",
    "\n",
    "    # Attenuating the filters\n",
    "    l_ear_filter[delay_l_ear] = 1\n",
    "    r_ear_filter[delay_r_ear] = attenuation_factor\n",
    "\n",
    "    l_chan = convolve(input_sound, l_ear_filter)\n",
    "    r_chan = convolve(input_sound, r_ear_filter)\n",
    "\n",
    "    if PLOT_GRAPHS:\n",
    "        plt.figure()\n",
    "        plt.title(\"Left and right ear filters\")\n",
    "        plt.plot(l_ear_filter)\n",
    "        plt.plot(r_ear_filter)\n",
    "\n",
    "    return np.vstack((l_chan, r_chan))\n",
    "\n",
    "\n",
    "left_45_crumble = left_45(input_sound_crumble, fs_crumble)\n",
    "sound(left_45_crumble, rate=fs_crumble, label=f\"{fname_crumble} 45° left\")\n",
    "\n",
    "if not SUBMISSION_MODE:\n",
    "    left_45_fly = left_45(input_sound_fly, fs_fly)\n",
    "    sound(left_45_fly, rate=fs_fly, label=f\"{fname_fly} 45° left\")\n",
    "\n",
    "    left_45_heli = left_45(input_sound_heli, fs_heli)\n",
    "    sound(left_45_heli, rate=fs_heli, label=f\"{fname_heli} 45° left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80° to the right\n",
    "def right_80(input_sound, fs):\n",
    "    radians = np.deg2rad(80)\n",
    "\n",
    "    # Calculating the distance from the left and right ears\n",
    "    dist_from_r_ear = np.sqrt(\n",
    "        (source_distance * np.cos(radians)) ** 2\n",
    "        + (source_distance * np.sin(radians) - head_width / 2) ** 2\n",
    "    )\n",
    "    dist_from_l_ear = np.sqrt(\n",
    "        (source_distance * np.cos(radians)) ** 2\n",
    "        + (source_distance * np.sin(radians) + head_width / 2) ** 2\n",
    "    )\n",
    "\n",
    "    # Calculating the delay for the left and right ears\n",
    "    delay_l_ear = int(dist_from_l_ear / speed_of_sound * fs)\n",
    "    delay_r_ear = int(dist_from_r_ear / speed_of_sound * fs)\n",
    "\n",
    "    # Setting up the left and right ear filters\n",
    "    l_ear_filter = np.zeros(delay_l_ear * 2)\n",
    "    r_ear_filter = np.zeros(delay_l_ear * 2)  # Using delay_l_ear for same size arrays\n",
    "\n",
    "    # Attenuating the filters\n",
    "    l_ear_filter[delay_l_ear] = attenuation_factor\n",
    "    r_ear_filter[delay_r_ear] = 1\n",
    "\n",
    "    l_chan = convolve(input_sound, l_ear_filter)\n",
    "    r_chan = convolve(input_sound, r_ear_filter)\n",
    "\n",
    "    if PLOT_GRAPHS:\n",
    "        plt.figure()\n",
    "        plt.title(\"Left and right ear filters\")\n",
    "        plt.plot(l_ear_filter)\n",
    "        plt.plot(r_ear_filter)\n",
    "\n",
    "    return np.vstack((l_chan, r_chan))\n",
    "\n",
    "\n",
    "right_80_crumble = right_80(input_sound_crumble, fs_crumble)\n",
    "sound(right_80_crumble, rate=fs_crumble, label=f\"{fname_crumble} 80° right\")\n",
    "\n",
    "if not SUBMISSION_MODE:\n",
    "    right_80_fly = left_45(input_sound_fly, fs_fly)\n",
    "    sound(right_80_fly, rate=fs_fly, label=f\"{fname_fly} 80° right\")\n",
    "\n",
    "    right_80_heli = left_45(input_sound_heli, fs_heli)\n",
    "    sound(right_80_heli, rate=fs_heli, label=f\"{fname_heli} 80° right\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 160° to the left\n",
    "def left_160(input_sound, fs):\n",
    "    radians = np.deg2rad(160)\n",
    "\n",
    "    # Calculating the distance from the left and right ears\n",
    "    dist_from_r_ear = np.sqrt(\n",
    "        (source_distance * np.cos(radians)) ** 2\n",
    "        + (source_distance * np.sin(radians) + head_width / 2) ** 2\n",
    "    )\n",
    "    dist_from_l_ear = np.sqrt(\n",
    "        (source_distance * np.cos(radians)) ** 2\n",
    "        + (source_distance * np.sin(radians) - head_width / 2) ** 2\n",
    "    )\n",
    "\n",
    "    # Calculating the delay for the left and right ears\n",
    "    delay_l_ear = int(dist_from_l_ear / speed_of_sound * fs)\n",
    "    delay_r_ear = int(dist_from_r_ear / speed_of_sound * fs)\n",
    "\n",
    "    # Setting up the left and right ear filters\n",
    "    l_ear_filter = np.zeros(delay_l_ear * 2)\n",
    "    r_ear_filter = np.zeros(delay_l_ear * 2)  # Using delay_l_ear for same size arrays\n",
    "\n",
    "    # Attenuating the filters\n",
    "    l_ear_filter[delay_l_ear] = 1\n",
    "    r_ear_filter[delay_r_ear] = attenuation_factor\n",
    "\n",
    "    l_chan = convolve(input_sound, l_ear_filter)\n",
    "    r_chan = convolve(input_sound, r_ear_filter)\n",
    "\n",
    "    if PLOT_GRAPHS:\n",
    "        plt.figure()\n",
    "        plt.title(\"Left and right ear filters\")\n",
    "        plt.plot(l_ear_filter)\n",
    "        plt.plot(r_ear_filter)\n",
    "\n",
    "    return np.vstack((l_chan, r_chan))\n",
    "\n",
    "\n",
    "left_160_crumble = left_160(input_sound_crumble, fs_crumble)\n",
    "sound(left_160_crumble, rate=fs_crumble, label=f\"{fname_crumble} 160° left\")\n",
    "\n",
    "if not SUBMISSION_MODE:\n",
    "    left_160_fly = left_160(input_sound_fly, fs_fly)\n",
    "    sound(left_160_fly, rate=fs_fly, label=f\"{fname_fly} 160° left\")\n",
    "\n",
    "    left_160_heli = left_160(input_sound_heli, fs_heli)\n",
    "    sound(left_160_heli, rate=fs_heli, label=f\"{fname_heli} 160° left\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "737a7645e6d8c0be2ab92f3ba7dafa96",
     "grade": false,
     "grade_id": "cell-f828ea3a2736c0c7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Part 2. Static sources using HRTFs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eb7eec159d12ed3eff1722a669eaf822",
     "grade": false,
     "grade_id": "cell-6c5fbbbb60e8cdac",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Download the HTTF archive from [https://drive.google.com/uc?export=download&id=1vFzSo-zlNFI-q2T9yvRRmOeZ-elZ8lW3 ]. In that directory you will also find code for the function load_hrtf which returns the left and right HRTF filters given as input a source’s azimuth and elevation. These filters will be much better than the ITD/ILD filters for localizing sounds.\n",
    "\n",
    "Apply the HRTFs on the given sources and create 3D sounds that correspond to the locations given above. For each source, you will beed to convolve it with the left and right HRTF of the desired position and generate two sounds, one for each channel. Verify that they sound correct using headphones; are they better than before? What differences do you observe? When you use these make sure that the sample rates of the HRTFs and the sounds you convolve them with match.  The HRTFs are sampled at 44.1kHz.\n",
    "\n",
    "Once again, just render one example before submission (the same as before so that we can compare)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the HRTF Filter to an input sound\n",
    "def hrtf(input_sound, azimuth, elevation):\n",
    "    left_filter, right_filter = hrtf_filter(azimuth, elevation)\n",
    "    left_chan = convolve(input_sound, left_filter)\n",
    "    right_chan = convolve(input_sound, right_filter)\n",
    "\n",
    "    if PLOT_GRAPHS:\n",
    "        plt.figure()\n",
    "        plt.title(\"Left and right ear filters\")\n",
    "        plt.plot(left_filter)\n",
    "        plt.plot(right_filter)\n",
    "        \n",
    "    return np.vstack((left_chan, right_chan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "30ccb0b59afcc2e336969d3ddccf7b68",
     "grade": true,
     "grade_id": "cell-7aa20c8c6db3869b",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Straight ahead\n",
    "hrtf_crumble = hrtf(input_sound_crumble, 0, 0)\n",
    "sound(hrtf_crumble, rate=fs_crumble, label=f\"{fname_crumble} HRTF straight ahead\")\n",
    "\n",
    "if not SUBMISSION_MODE:\n",
    "    hrtf_fly = hrtf(input_sound_fly, 0, 0)\n",
    "    sound(hrtf_fly, rate=fs_fly, label=f\"{fname_fly} HRTF straight ahead\")\n",
    "\n",
    "    hrtf_heli = hrtf(input_sound_heli, 0, 0)\n",
    "    sound(hrtf_heli, rate=fs_heli, label=f\"{fname_heli} HRTF straight ahead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 45° to the left\n",
    "hrtf_crumble = hrtf(input_sound_crumble, -45, 0)\n",
    "sound(hrtf_crumble, rate=fs_crumble, label=f\"{fname_crumble} HRTF 45° left\")\n",
    "\n",
    "if not SUBMISSION_MODE:\n",
    "    hrtf_fly = hrtf(input_sound_fly, -45, 0)\n",
    "    sound(hrtf_fly, rate=fs_fly, label=f\"{fname_fly} HRTF 45° left\")\n",
    "\n",
    "    hrtf_heli = hrtf(input_sound_heli, -45, 0)\n",
    "    sound(hrtf_heli, rate=fs_heli, label=f\"{fname_heli} HRTF 45° left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80° to the right\n",
    "hrtf_crumble = hrtf(input_sound_crumble, 80, 0)\n",
    "sound(hrtf_crumble, rate=fs_crumble, label=f\"{fname_crumble} HRTF 80° right\")\n",
    "\n",
    "if not SUBMISSION_MODE:\n",
    "    hrtf_fly = hrtf(input_sound_fly, 80, 0)\n",
    "    sound(hrtf_fly, rate=fs_fly, label=f\"{fname_fly} HRTF 80° right\")\n",
    "\n",
    "    hrtf_heli = hrtf(input_sound_heli, 80, 0)\n",
    "    sound(hrtf_heli, rate=fs_heli, label=f\"{fname_heli} HRTF 80° right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#160° to the left\n",
    "hrtf_crumble = hrtf(input_sound_crumble, -160, 0)\n",
    "sound(hrtf_crumble, rate=fs_crumble, label=f\"{fname_crumble} HRTF 160° left\")\n",
    "\n",
    "if not SUBMISSION_MODE:\n",
    "    hrtf_fly = hrtf(input_sound_fly, -160, 0)\n",
    "    sound(hrtf_fly, rate=fs_fly, label=f\"{fname_fly} HRTF 160° left\")\n",
    "\n",
    "    hrtf_heli = hrtf(input_sound_heli, -160, 0)\n",
    "    sound(hrtf_heli, rate=fs_heli, label=f\"{fname_heli} HRTF 160° left\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "While experimenting with the HRTF filters, I was surprised when I found the straight ahead sound felt a little less prominent in the lower frequencies as compared to both the original sound as well as the filters designed in part 1. This made the sound a little thinner than its counterparts. When I was listening to the sounds (HRTF) positioned in locations other than straight ahead, I felt like the sense of space was a lot more believable than through the filters in part 1. This is not to discredit the filters designed in part 1 as they too sounded quite believable as if they were in different locations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "09136705ec12de8e825442459f422b58",
     "grade": false,
     "grade_id": "cell-c2eb36b7ccda595f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Part 3. Dynamic Sources with HRTFs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8ae73ad74b6ec19d56c83a9400dcfb4b",
     "grade": false,
     "grade_id": "cell-63eaf3eb61463897",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In this part you will need to make a moving sound source. In order to do so we will make use of a fast convolution routine based on your STFT code from lab 1 (ha, you thought you were done with that!). In order to perform fast convolution we can perform an STFT of the sound to use, multiply each time frame of this transform with the DFT of the filter that we want  to impose and then use overlap add to transform back to the time domain.\n",
    "\n",
    "Start by taking each sound from above, and apply your STFT on it. Make sure that the size of the transform is the same as the HRTF’s filter length. The hop size should be the same as the DFT size and you will need to zero pad by as much as the DFT size in order to facilitate the tail of the convolution. Do not use an analysis/synthesis window.\n",
    "\n",
    "Once you compute this STFT, go through its every time frame and element-wise multiply it with the desired HRTF filter to generate the STFT of the left and right sounds. Figure out which HRTF angle to multiply each frame with so that by the end of the sound you will have made it go around your head.\n",
    "\n",
    "Once you perform these operations you will have generated two STFT matrices, one for the left channel and one for the right. Use your inverse STFT routine and play the stereo sound through your headphones. You should hear a convincing rendering of the original sounds circling around your head.\n",
    "\n",
    "Submit only one of the sounds, but make sure you try it on all and that it sounds ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STFT and ISTFT from lab 1\n",
    "def stft(input_sound, dft_size, hop_size, zero_pad, window):\n",
    "    # Creating the n-1 frames\n",
    "    frames = []\n",
    "    idx = 0\n",
    "    for idx in range(0, len(input_sound) - dft_size, hop_size):\n",
    "        frames.append(np.multiply(input_sound[idx:idx + dft_size], window))\n",
    "    idx += hop_size\n",
    "\n",
    "    # Creating the last frame accounting for padding\n",
    "    last_frame = np.multiply(\n",
    "        np.append(input_sound[idx:-1],\n",
    "                  np.zeros(idx + dft_size - len(input_sound) + 1)), window)\n",
    "    frames.append(last_frame)\n",
    "\n",
    "    # Convert to numpy array\n",
    "    frames = np.array(frames, dtype=float)\n",
    "\n",
    "    # Compute the DFT of each frame\n",
    "    dft_frames = np.fft.rfft(frames, dft_size + zero_pad)\n",
    "    return dft_frames\n",
    "\n",
    "def istft(stft_output, dft_size, hop_size, zero_pad):\n",
    "    # Initializing the signal length\n",
    "    signal_length = (stft_output.shape[0] * hop_size) + dft_size + zero_pad\n",
    "    signal = np.zeros(signal_length)\n",
    "\n",
    "    for i in range(stft_output.shape[0]):\n",
    "        original_signal = np.fft.irfft(stft_output[i, :], dft_size + zero_pad)\n",
    "        start = i * hop_size\n",
    "        end = start + original_signal.shape[0]\n",
    "        signal[start:end] += original_signal\n",
    "\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a 360° sound\n",
    "def make_360(input_sound, dft_size, hop_size, zero_pad, window):\n",
    "    input_sound_stft = stft(input_sound, dft_size, hop_size, zero_pad, window)\n",
    "\n",
    "    # Making sure the the size of the transform is the same as the HRTF’s filter length\n",
    "    left_chan = np.zeros(input_sound_stft.shape, dtype=complex)\n",
    "    right_chan = np.zeros(input_sound_stft.shape, dtype=complex)\n",
    "\n",
    "    for i in range(input_sound_stft.shape[0]):\n",
    "        azimuth = (i / input_sound_stft.shape[0]) * 360\n",
    "        left_filter, right_filter = hrtf_filter(azimuth, 0)  # Choose the appropriate filter \n",
    "        \n",
    "        # Applying a fft to the filter\n",
    "        left_chan[i] = input_sound_stft[i] * np.fft.rfft(left_filter, dft_size * 2)\n",
    "        right_chan[i] = input_sound_stft[i] * np.fft.rfft(right_filter, dft_size * 2)\n",
    "\n",
    "    # Inverse STFT routine\n",
    "    left_chan = istft(left_chan, dft_size, hop_size, zero_pad)\n",
    "    right_chan = istft(right_chan, dft_size, hop_size, zero_pad)\n",
    "\n",
    "    return np.vstack((left_chan, right_chan))\n",
    "\n",
    "dft_size = 256\n",
    "hop_size = dft_size\n",
    "zero_pad = dft_size\n",
    "window = 1\n",
    "\n",
    "crumble_360 = make_360(input_sound_crumble, dft_size, hop_size, zero_pad, window)\n",
    "sound(crumble_360, rate=fs_crumble, label=f\"{fname_crumble} 360° effect\")\n",
    "\n",
    "if not SUBMISSION_MODE:\n",
    "    fly_360 = make_360(input_sound_fly, dft_size, hop_size, zero_pad, window)\n",
    "    sound(fly_360, rate=fs_fly, label=f\"{fname_fly} 360° effect\")\n",
    "\n",
    "    heli_360 = make_360(input_sound_heli, dft_size, hop_size, zero_pad, window)\n",
    "    sound(heli_360, rate=fs_heli, label=f\"{fname_heli} 360° effect\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3ff1a53eda0063ee9d7fb15331122010",
     "grade": false,
     "grade_id": "cell-b0124588fbfe89bb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Part 4. Extra credit (required for 4-hour credit registrants)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "91ff910e32fe396a3d00038e9d01090f",
     "grade": false,
     "grade_id": "cell-b3414fb1e822c1df",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Use the file in [https://drive.google.com/uc?export=download&id=1bxQkXcGa57S3G7IRWu9urS-jCPdf5Pif ] to make a short story. This is a 7-channel file of a scene from a really bad B-movie. Each channel contains a different sound. If you play that sound you probably won’t hear most of the content since you won’t have a 7 speaker setup, import it in a multi-channel editor such as Audacity and you will get a sense of what’s in there. Since it sounds so boring you need to add some reverb and 3D-locate the sounds so that it sounds more exciting. Try to make it sound better using what we have done so far. Keep in mind that you can add different amounts of reverb for each sound, and you can dynamically 3D place them as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5faf496e989916afedad8ef8b7263784",
     "grade": true,
     "grade_id": "cell-58aead3226c4d49a",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
